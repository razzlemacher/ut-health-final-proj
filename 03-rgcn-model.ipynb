{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "513aba00",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "76391734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version:  2.6.0+cpu\n",
      "torch geometric version:  2.6.1\n",
      "torch cuda version:  None\n",
      "torch cuda available:  False\n",
      "Pandas version: 2.2.3\n",
      "Numpy version: 2.2.4\n",
      "Matplotlib version: 3.10.1\n",
      "NetworkX version: 3.4.2\n",
      "\n",
      "Removed truncation of columns\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# import torch geometric\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.nn import GCNConv, GATConv, SAGEConv, GraphConv\n",
    "# from torch_geometric.nn import MessagePassing\n",
    "# from torch_geometric.nn import global_mean_pool, global_max_pool, global_add_pool\n",
    "# from torch_geometric.utils import degree, to_dense_adj, to_dense_batch, to_undirected\n",
    "# from torch_geometric.utils import from_networkx, to_networkx\n",
    "# from torch_geometric.utils import negative_sampling, remove_self_loops, add_self_loops\n",
    "# from torch_geometric.utils import dropout_adj, to_undirected, add_self_loops\n",
    "# from torch_geometric.utils import to_dense_adj, to_dense_batch, dense_to_sparse\n",
    "\n",
    "# print versions\n",
    "print(\"torch version: \", torch.__version__)\n",
    "print(\"torch geometric version: \", torch_geometric.__version__)\n",
    "print(\"torch cuda version: \", torch.version.cuda)\n",
    "print(\"torch cuda available: \", torch.cuda.is_available())\n",
    "# print(\"torch cuda device count: \", torch.cuda.device_count())\n",
    "# print(\"torch cuda current device name: \", torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "\n",
    "# print versions\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"Numpy version: {np.__version__}\")\n",
    "print(f\"Matplotlib version: {matplotlib.__version__}\")\n",
    "print(f\"NetworkX version: {nx.__version__}\")\n",
    "\n",
    "# set pandas display options to show all columns and rows without truncation\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "print(\"\\nRemoved truncation of columns\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1434cc4",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6acf46",
   "metadata": {},
   "source": [
    "## Load networkx graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bef209e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading graph from d:\\Repos\\ut-health-final-proj\\pickle\\max_20000_nodes_graph.gpickle...\n",
      "Graph loaded. Number of nodes: 17654, number of edges: 172728\n"
     ]
    }
   ],
   "source": [
    "# load the networkx graph\n",
    "def load_graph(graph_path):\n",
    "    with open(graph_path, 'rb') as f:\n",
    "        graph = pickle.load(f)\n",
    "    return graph\n",
    "\n",
    "CURR_DIR_PATH = os.getcwd()\n",
    "PICKLE_GRAPH_FILE_NAME = f\"{CURR_DIR_PATH}\\\\pickle\\\\max_20000_nodes_graph.gpickle\"\n",
    "PICKLE_GRAPH_FILE_NAME = os.path.abspath(PICKLE_GRAPH_FILE_NAME)\n",
    "\n",
    "print(f\"Loading graph from {PICKLE_GRAPH_FILE_NAME}...\")\n",
    "ntx_graph = load_graph(PICKLE_GRAPH_FILE_NAME)\n",
    "print(f\"Graph loaded. Number of nodes: {ntx_graph.number_of_nodes()}, number of edges: {ntx_graph.number_of_edges()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d981189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node counts: {'patient': 11630, 'diagnosis': 4680, 'procedure': 1344}\n",
      "Edge counts: {'has_diagnosis': 123987, 'has_procedure': 48741}\n"
     ]
    }
   ],
   "source": [
    "# count nodes of type patient, diagnosis and procedure\n",
    "def count_node_types(graph):\n",
    "    node_types = {}\n",
    "    for node in graph.nodes():\n",
    "        node_type = graph.nodes[node]['type']\n",
    "        if node_type not in node_types:\n",
    "            node_types[node_type] = 0\n",
    "        node_types[node_type] += 1\n",
    "    return node_types\n",
    "\n",
    "node_types = count_node_types(ntx_graph)\n",
    "print(f\"Node counts: {node_types}\")\n",
    "\n",
    "# count edges named had_procedure, has_diagnosis\n",
    "def count_edge_types(graph):\n",
    "    edge_types = {}\n",
    "    for u, v, key in graph.edges(keys=True):\n",
    "        edge_type = graph.edges[u, v, key]['relation']\n",
    "        if edge_type not in edge_types:\n",
    "            edge_types[edge_type] = 0\n",
    "        edge_types[edge_type] += 1\n",
    "    return edge_types\n",
    "\n",
    "edge_types = count_edge_types(ntx_graph)\n",
    "print(f\"Edge counts: {edge_types}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5433ec",
   "metadata": {},
   "source": [
    "## Load patient node similarity dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "709c689b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading patient similarity dataframe from d:\\Repos\\ut-health-final-proj\\pickle\\max_20000_nodes_similarity.gpickle...\n",
      "Patient similarity dataframe loaded. Number of rows: 1288402\n"
     ]
    }
   ],
   "source": [
    "# load the patient similarity dataframe\n",
    "def load_patient_similarity_df(df_path):\n",
    "    with open(df_path, 'rb') as f:\n",
    "        df = pickle.load(f)\n",
    "    return df\n",
    "\n",
    "CURR_DIR_PATH = os.getcwd()\n",
    "PATIENT_SIMILARITY_DF_FILE_NAME = f\"{CURR_DIR_PATH}\\\\pickle\\\\max_20000_nodes_similarity.gpickle\"\n",
    "PATIENT_SIMILARITY_DF_FILE_NAME = os.path.abspath(PATIENT_SIMILARITY_DF_FILE_NAME)\n",
    "\n",
    "print(f\"Loading patient similarity dataframe from {PATIENT_SIMILARITY_DF_FILE_NAME}...\")\n",
    "patient_similarity_df = load_patient_similarity_df(PATIENT_SIMILARITY_DF_FILE_NAME)\n",
    "print(f\"Patient similarity dataframe loaded. Number of rows: {patient_similarity_df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8da7142e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient1</th>\n",
       "      <th>patient2</th>\n",
       "      <th>patient1_id</th>\n",
       "      <th>patient2_id</th>\n",
       "      <th>jaccard_similarity</th>\n",
       "      <th>same_gender</th>\n",
       "      <th>same_age_bucket</th>\n",
       "      <th>is_similar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>patient-4074</td>\n",
       "      <td>patient-10139</td>\n",
       "      <td>4074</td>\n",
       "      <td>10139</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9670</th>\n",
       "      <td>patient-4074</td>\n",
       "      <td>patient-26572</td>\n",
       "      <td>4074</td>\n",
       "      <td>26572</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16410</th>\n",
       "      <td>patient-90889</td>\n",
       "      <td>patient-84020</td>\n",
       "      <td>90889</td>\n",
       "      <td>84020</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17072</th>\n",
       "      <td>patient-90889</td>\n",
       "      <td>patient-67648</td>\n",
       "      <td>90889</td>\n",
       "      <td>67648</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19221</th>\n",
       "      <td>patient-90889</td>\n",
       "      <td>patient-6138</td>\n",
       "      <td>90889</td>\n",
       "      <td>6138</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            patient1       patient2  patient1_id  patient2_id  \\\n",
       "423     patient-4074  patient-10139         4074        10139   \n",
       "9670    patient-4074  patient-26572         4074        26572   \n",
       "16410  patient-90889  patient-84020        90889        84020   \n",
       "17072  patient-90889  patient-67648        90889        67648   \n",
       "19221  patient-90889   patient-6138        90889         6138   \n",
       "\n",
       "       jaccard_similarity  same_gender  same_age_bucket  is_similar  \n",
       "423              0.304348        False            False        True  \n",
       "9670             0.300000         True             True        True  \n",
       "16410            0.344828         True            False        True  \n",
       "17072            0.400000        False            False        True  \n",
       "19221            0.333333         True            False        True  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patient_similarity_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd23b146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_node</th>\n",
       "      <th>target_node</th>\n",
       "      <th>patient1_id</th>\n",
       "      <th>patient2_id</th>\n",
       "      <th>jaccard_similarity</th>\n",
       "      <th>same_gender</th>\n",
       "      <th>same_age_bucket</th>\n",
       "      <th>is_similar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>patient-4074</td>\n",
       "      <td>patient-10139</td>\n",
       "      <td>4074</td>\n",
       "      <td>10139</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9670</th>\n",
       "      <td>patient-4074</td>\n",
       "      <td>patient-26572</td>\n",
       "      <td>4074</td>\n",
       "      <td>26572</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16410</th>\n",
       "      <td>patient-90889</td>\n",
       "      <td>patient-84020</td>\n",
       "      <td>90889</td>\n",
       "      <td>84020</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17072</th>\n",
       "      <td>patient-90889</td>\n",
       "      <td>patient-67648</td>\n",
       "      <td>90889</td>\n",
       "      <td>67648</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19221</th>\n",
       "      <td>patient-90889</td>\n",
       "      <td>patient-6138</td>\n",
       "      <td>90889</td>\n",
       "      <td>6138</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         source_node    target_node  patient1_id  patient2_id  \\\n",
       "423     patient-4074  patient-10139         4074        10139   \n",
       "9670    patient-4074  patient-26572         4074        26572   \n",
       "16410  patient-90889  patient-84020        90889        84020   \n",
       "17072  patient-90889  patient-67648        90889        67648   \n",
       "19221  patient-90889   patient-6138        90889         6138   \n",
       "\n",
       "       jaccard_similarity  same_gender  same_age_bucket  is_similar  \n",
       "423              0.304348        False            False        True  \n",
       "9670             0.300000         True             True        True  \n",
       "16410            0.344828         True            False        True  \n",
       "17072            0.400000        False            False        True  \n",
       "19221            0.333333         True            False        True  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rename column patient1 to source and patient2 to target\n",
    "patient_similarity_df.rename(columns={'patient1': 'source_node', 'patient2': 'target_node'}, inplace=True)\n",
    "patient_similarity_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b07df0",
   "metadata": {},
   "source": [
    "# Create R-GCN and train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b798fed9",
   "metadata": {},
   "source": [
    "### DEBUG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cb29d9fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node_types: {'patient': [], 'diagnosis': [], 'procedure': []}\n",
      "node_mappings: {'patient': {}, 'diagnosis': {}, 'procedure': {}}\n",
      "node: patient-4074\n",
      "attr: {'gender': 'M', 'age_bucket': 80, 'hadm_id': 137421, 'type': 'patient'}\n",
      "node_type: patient\n",
      "node_mappings[patient][patient-4074]: 0\n",
      "node_mappings[node_type][node]: 0\n",
      "node_mappings[patient][patient-90889]: 1\n",
      "node_mappings[node_type][node]: 1\n",
      "node_mappings[patient][patient-72753]: 2\n",
      "node_mappings[node_type][node]: 2\n"
     ]
    }
   ],
   "source": [
    "# Get node types\n",
    "node_types = {node_type: [] for node_type in ['patient', 'diagnosis', 'procedure']}\n",
    "print(f\"node_types: {node_types}\")\n",
    "\n",
    "    \n",
    "# Create mappings from original node IDs to new indices for each node type\n",
    "node_mappings = {node_type: {} for node_type in node_types}\n",
    "\n",
    "print(f\"node_mappings: {node_mappings}\")\n",
    "i=0\n",
    "for node, attr in ntx_graph.nodes(data=True):\n",
    "    node_type = attr['type']\n",
    "    if i ==0:\n",
    "        print(f\"node: {node}\")\n",
    "        print(f\"attr: {attr}\")\n",
    "        print(f\"node_type: {node_type}\")\n",
    "\n",
    "    if node not in node_mappings[node_type]:\n",
    "        node_mappings[node_type][node] = len(node_mappings[node_type])\n",
    "\n",
    "        i+=1\n",
    "        print(f\"node_mappings[{node_type}][{node}]: {node_mappings[node_type][node]}\")\n",
    "        print(f\"node_mappings[node_type][node]: {node_mappings[node_type][node]}\")\n",
    "\n",
    "    if i==3:\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83dad690",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8125868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting NetworkX graph to HeteroData...\n",
      "Processing similarity data...\n",
      "Created 50000 training pairs\n",
      "Training model...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"Tried to collect 'edge_index' but did not find any occurrences of it in any node and/or edge type\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 169\u001b[39m\n\u001b[32m    167\u001b[39m num_epochs = \u001b[32m50\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[32m--> \u001b[39m\u001b[32m169\u001b[39m     loss = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    170\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (epoch + \u001b[32m1\u001b[39m) % \u001b[32m5\u001b[39m == \u001b[32m0\u001b[39m:\n\u001b[32m    171\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch+\u001b[32m1\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m02d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 154\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    151\u001b[39m optimizer.zero_grad()\n\u001b[32m    153\u001b[39m \u001b[38;5;66;03m# Get embeddings\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m embeddings = model(data.x_dict, \u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43medge_index_dict\u001b[49m)\n\u001b[32m    156\u001b[39m \u001b[38;5;66;03m# Compute loss\u001b[39;00m\n\u001b[32m    157\u001b[39m loss = criterion(embeddings, sim_pairs, sim_labels)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Razal\\.conda\\envs\\health-a8\\Lib\\site-packages\\torch_geometric\\data\\hetero_data.py:161\u001b[39m, in \u001b[36mHeteroData.__getattr__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m    159\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m._global_store, key)\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(re.search(\u001b[33m'\u001b[39m\u001b[33m_dict$\u001b[39m\u001b[33m'\u001b[39m, key)):\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m has no \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    163\u001b[39m                      \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mattribute \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Razal\\.conda\\envs\\health-a8\\Lib\\site-packages\\torch_geometric\\data\\hetero_data.py:565\u001b[39m, in \u001b[36mHeteroData.collect\u001b[39m\u001b[34m(self, key, allow_empty)\u001b[39m\n\u001b[32m    563\u001b[39m         mapping[subtype] = \u001b[38;5;28mgetattr\u001b[39m(store, key)\n\u001b[32m    564\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_empty \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapping) == \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m565\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTried to collect \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m but did not find any \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    566\u001b[39m                    \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33moccurrences of it in any node and/or edge type\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    567\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m mapping\n",
      "\u001b[31mKeyError\u001b[39m: \"Tried to collect 'edge_index' but did not find any occurrences of it in any node and/or edge type\""
     ]
    }
   ],
   "source": [
    "# Convert NetworkX graph to PyTorch Geometric HeteroData\n",
    "def convert_to_hetero_data(nx_graph):\n",
    "    data = HeteroData()\n",
    "    \n",
    "    # create node types {'patient': [], 'diagnosis': [], 'procedure': []}\n",
    "    node_types = {node_type: [] for node_type in ['patient', 'diagnosis', 'procedure']}\n",
    "\n",
    "    \n",
    "    # Create mappings from original node IDs to new indices for each node type\n",
    "    # {'patient': {}, 'diagnosis': {}, 'procedure': {}}\n",
    "    node_mappings = {node_type: {} for node_type in node_types}\n",
    "\n",
    "    for node, attr in nx_graph.nodes(data=True):\n",
    "        node_type = attr['type']\n",
    "        if node not in node_mappings[node_type]:\n",
    "            node_mappings[node_type][node] = len(node_mappings[node_type])\n",
    "    \n",
    "    # Add node features (just using one-hot encoding for simplicity)\n",
    "    for node_type, mapping in node_mappings.items():\n",
    "        num_nodes = len(mapping)\n",
    "        # Use one-hot encoding as node features\n",
    "        data[node_type].x = torch.eye(num_nodes)\n",
    "    \n",
    "    # Add edges\n",
    "    edge_types = [('patient', 'has_diagnosis', 'diagnosis'), \n",
    "                  ('patient', 'has_procedure', 'procedure')]\n",
    "    \n",
    "    for src_type, relation, dst_type in edge_types:\n",
    "        edge_indices = [[], []]\n",
    "        for u, v, key, attr in nx_graph.edges(keys=True, data=True):\n",
    "            if attr['relation'] == relation.replace('_', ' '):\n",
    "                # Find source and destination nodes with correct types\n",
    "                src_node_type = nx_graph.nodes[u]['type']\n",
    "                dst_node_type = nx_graph.nodes[v]['type']\n",
    "                \n",
    "                if src_node_type == src_type and dst_node_type == dst_type:\n",
    "                    edge_indices[0].append(node_mappings[src_type][u])\n",
    "                    edge_indices[1].append(node_mappings[dst_type][v])\n",
    "                elif src_node_type == dst_type and dst_node_type == src_type:\n",
    "                    # In case the edge direction is reversed\n",
    "                    edge_indices[0].append(node_mappings[dst_type][v])\n",
    "                    edge_indices[1].append(node_mappings[src_type][u])\n",
    "        \n",
    "        if len(edge_indices[0]) > 0:\n",
    "            data[src_type, relation, dst_type].edge_index = torch.tensor(edge_indices)\n",
    "    \n",
    "    return data, node_mappings\n",
    "\n",
    "# Create RGCN model for contrastive learning\n",
    "class RGCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels, metadata):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Initialize the GNN encoders\n",
    "        self.conv1 = torch_geometric.nn.HeteroConv({\n",
    "            ('patient', 'has_diagnosis', 'diagnosis'): GraphConv(-1, hidden_channels),\n",
    "            ('patient', 'has_procedure', 'procedure'): GraphConv(-1, hidden_channels),\n",
    "            ('diagnosis', 'rev_has_diagnosis', 'patient'): GraphConv(-1, hidden_channels),\n",
    "            ('procedure', 'rev_has_procedure', 'patient'): GraphConv(-1, hidden_channels)\n",
    "        })\n",
    "        \n",
    "        self.conv2 = torch_geometric.nn.HeteroConv({\n",
    "            ('patient', 'has_diagnosis', 'diagnosis'): GraphConv(hidden_channels, hidden_channels),\n",
    "            ('patient', 'has_procedure', 'procedure'): GraphConv(hidden_channels, hidden_channels),\n",
    "            ('diagnosis', 'rev_has_diagnosis', 'patient'): GraphConv(hidden_channels, hidden_channels),\n",
    "            ('procedure', 'rev_has_procedure', 'patient'): GraphConv(hidden_channels, hidden_channels)\n",
    "        })\n",
    "        \n",
    "        # Projection head for contrastive learning\n",
    "        self.patient_proj = nn.Sequential(\n",
    "            nn.Linear(hidden_channels, hidden_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_channels, out_channels)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        # First layer\n",
    "        x_dict = self.conv1(x_dict, edge_index_dict)\n",
    "        x_dict = {key: F.relu(x) for key, x in x_dict.items()}\n",
    "        \n",
    "        # Second layer\n",
    "        x_dict = self.conv2(x_dict, edge_index_dict)\n",
    "        x_dict = {key: F.relu(x) for key, x in x_dict.items()}\n",
    "        \n",
    "        # Project patient embeddings for contrastive learning\n",
    "        patient_emb = self.patient_proj(x_dict['patient'])\n",
    "        return patient_emb\n",
    "\n",
    "# Create a contrastive loss function\n",
    "class ContrastiveLoss(nn.Module):\n",
    "    def __init__(self, margin=0.5):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "        \n",
    "    def forward(self, embeddings, pairs, labels):\n",
    "        # Extract embeddings for pairs\n",
    "        embeddings1 = embeddings[pairs[:, 0]]\n",
    "        embeddings2 = embeddings[pairs[:, 1]]\n",
    "        \n",
    "        # Calculate Euclidean distance\n",
    "        distances = F.pairwise_distance(embeddings1, embeddings2)\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = (1 - labels) * torch.pow(distances, 2) + \\\n",
    "               labels * torch.pow(torch.clamp(self.margin - distances, min=0.0), 2)\n",
    "        return loss.mean()\n",
    "\n",
    "# Process NetworkX graph\n",
    "print(\"Converting NetworkX graph to HeteroData...\")\n",
    "data, node_mappings = convert_to_hetero_data(ntx_graph)\n",
    "\n",
    "# Add reverse edges to make the graph undirected\n",
    "transform = T.ToUndirected()\n",
    "data = transform(data)\n",
    "\n",
    "# Find the node IDs in the patient_similarity_df\n",
    "# Create a lookup from node name to node index\n",
    "patient_node_lookup = {node: idx for node, idx in node_mappings['patient'].items()}\n",
    "\n",
    "# Process similarity data for training\n",
    "print(\"Processing similarity data...\")\n",
    "sim_pairs = []\n",
    "sim_labels = []\n",
    "\n",
    "# Process a subset of pairs for efficiency in this example\n",
    "subset_df = patient_similarity_df.sample(min(50000, len(patient_similarity_df)))\n",
    "\n",
    "for _, row in subset_df.iterrows():\n",
    "    source = row['source_node']\n",
    "    target = row['target_node']\n",
    "    if source in patient_node_lookup and target in patient_node_lookup:\n",
    "        source_idx = patient_node_lookup[source]\n",
    "        target_idx = patient_node_lookup[target]\n",
    "        sim_pairs.append([source_idx, target_idx])\n",
    "        sim_labels.append(1.0 if row['is_similar'] else 0.0)\n",
    "\n",
    "sim_pairs = torch.tensor(sim_pairs)\n",
    "sim_labels = torch.tensor(sim_labels)\n",
    "\n",
    "print(f\"Created {len(sim_pairs)} training pairs\")\n",
    "\n",
    "# Create the model\n",
    "hidden_channels = 64\n",
    "out_channels = 32\n",
    "model = RGCN(hidden_channels, out_channels, data.metadata())\n",
    "\n",
    "# Set up optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = ContrastiveLoss()\n",
    "\n",
    "# Training loop\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Get embeddings\n",
    "    embeddings = model(data.x_dict, data.edge_index_dict)\n",
    "    \n",
    "    # Compute loss\n",
    "    loss = criterion(embeddings, sim_pairs, sim_labels)\n",
    "    \n",
    "    # Backpropagation\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.item()\n",
    "\n",
    "# Train the model\n",
    "print(\"Training model...\")\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    loss = train()\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print(f'Epoch: {epoch+1:02d}, Loss: {loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e821907c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
