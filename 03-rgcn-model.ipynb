{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "513aba00",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76391734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version:  2.6.0+cpu\n",
      "torch geometric version:  2.6.1\n",
      "torch cuda version:  None\n",
      "torch cuda available:  False\n",
      "Pandas version: 2.2.3\n",
      "Numpy version: 2.2.4\n",
      "Matplotlib version: 3.10.1\n",
      "NetworkX version: 3.4.2\n",
      "\n",
      "Removed truncation of columns\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib\n",
    "import torch\n",
    "import torch_geometric\n",
    "\n",
    "# print versions\n",
    "print(\"torch version: \", torch.__version__)\n",
    "print(\"torch geometric version: \", torch_geometric.__version__)\n",
    "print(\"torch cuda version: \", torch.version.cuda)\n",
    "print(\"torch cuda available: \", torch.cuda.is_available())\n",
    "# print(\"torch cuda device count: \", torch.cuda.device_count())\n",
    "# print(\"torch cuda current device name: \", torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "\n",
    "# print versions\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"Numpy version: {np.__version__}\")\n",
    "print(f\"Matplotlib version: {matplotlib.__version__}\")\n",
    "print(f\"NetworkX version: {nx.__version__}\")\n",
    "\n",
    "# set pandas display options to show all columns and rows without truncation\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "print(\"\\nRemoved truncation of columns\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1434cc4",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6acf46",
   "metadata": {},
   "source": [
    "## Load networkx graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bef209e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading graph from d:\\Repos\\ut-health-final-proj\\pickle\\max_20000_nodes_graph.gpickle...\n",
      "Graph loaded. Number of nodes: 17654, number of edges: 172728\n"
     ]
    }
   ],
   "source": [
    "# load the networkx graph\n",
    "def load_graph(graph_path):\n",
    "    with open(graph_path, 'rb') as f:\n",
    "        graph = pickle.load(f)\n",
    "    return graph\n",
    "\n",
    "CURR_DIR_PATH = os.getcwd()\n",
    "PICKLE_GRAPH_FILE_NAME = f\"{CURR_DIR_PATH}\\\\pickle\\\\max_20000_nodes_graph.gpickle\"\n",
    "PICKLE_GRAPH_FILE_NAME = os.path.abspath(PICKLE_GRAPH_FILE_NAME)\n",
    "\n",
    "print(f\"Loading graph from {PICKLE_GRAPH_FILE_NAME}...\")\n",
    "ntx_graph = load_graph(PICKLE_GRAPH_FILE_NAME)\n",
    "print(f\"Graph loaded. Number of nodes: {ntx_graph.number_of_nodes()}, number of edges: {ntx_graph.number_of_edges()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d981189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node counts: {'patient': 11630, 'diagnosis': 4680, 'procedure': 1344}\n",
      "Edge counts: {'has_diagnosis': 123987, 'has_procedure': 48741}\n"
     ]
    }
   ],
   "source": [
    "# count nodes of type patient, diagnosis and procedure\n",
    "def count_node_types(graph):\n",
    "    node_types = {}\n",
    "    for node in graph.nodes():\n",
    "        node_type = graph.nodes[node]['type']\n",
    "        if node_type not in node_types:\n",
    "            node_types[node_type] = 0\n",
    "        node_types[node_type] += 1\n",
    "    return node_types\n",
    "\n",
    "node_types = count_node_types(ntx_graph)\n",
    "print(f\"Node counts: {node_types}\")\n",
    "\n",
    "# count edges named had_procedure, has_diagnosis\n",
    "def count_edge_types(graph):\n",
    "    edge_types = {}\n",
    "    for u, v, key in graph.edges(keys=True):\n",
    "        edge_type = graph.edges[u, v, key]['relation']\n",
    "        if edge_type not in edge_types:\n",
    "            edge_types[edge_type] = 0\n",
    "        edge_types[edge_type] += 1\n",
    "    return edge_types\n",
    "\n",
    "edge_types = count_edge_types(ntx_graph)\n",
    "print(f\"Edge counts: {edge_types}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5433ec",
   "metadata": {},
   "source": [
    "## Load patient node similarity dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "709c689b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading patient similarity dataframe from d:\\Repos\\ut-health-final-proj\\pickle\\max_20000_nodes_similarity.gpickle...\n",
      "Patient similarity dataframe loaded. Number of rows: 1288402\n"
     ]
    }
   ],
   "source": [
    "# load the patient similarity dataframe\n",
    "def load_patient_similarity_df(df_path):\n",
    "    with open(df_path, 'rb') as f:\n",
    "        df = pickle.load(f)\n",
    "    return df\n",
    "\n",
    "CURR_DIR_PATH = os.getcwd()\n",
    "PATIENT_SIMILARITY_DF_FILE_NAME = f\"{CURR_DIR_PATH}\\\\pickle\\\\max_20000_nodes_similarity.gpickle\"\n",
    "PATIENT_SIMILARITY_DF_FILE_NAME = os.path.abspath(PATIENT_SIMILARITY_DF_FILE_NAME)\n",
    "\n",
    "print(f\"Loading patient similarity dataframe from {PATIENT_SIMILARITY_DF_FILE_NAME}...\")\n",
    "patient_similarity_df = load_patient_similarity_df(PATIENT_SIMILARITY_DF_FILE_NAME)\n",
    "print(f\"Patient similarity dataframe loaded. Number of rows: {patient_similarity_df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8da7142e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient1</th>\n",
       "      <th>patient2</th>\n",
       "      <th>patient1_id</th>\n",
       "      <th>patient2_id</th>\n",
       "      <th>jaccard_similarity</th>\n",
       "      <th>same_gender</th>\n",
       "      <th>same_age_bucket</th>\n",
       "      <th>is_similar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>patient-4074</td>\n",
       "      <td>patient-10139</td>\n",
       "      <td>4074</td>\n",
       "      <td>10139</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9670</th>\n",
       "      <td>patient-4074</td>\n",
       "      <td>patient-26572</td>\n",
       "      <td>4074</td>\n",
       "      <td>26572</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16410</th>\n",
       "      <td>patient-90889</td>\n",
       "      <td>patient-84020</td>\n",
       "      <td>90889</td>\n",
       "      <td>84020</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17072</th>\n",
       "      <td>patient-90889</td>\n",
       "      <td>patient-67648</td>\n",
       "      <td>90889</td>\n",
       "      <td>67648</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19221</th>\n",
       "      <td>patient-90889</td>\n",
       "      <td>patient-6138</td>\n",
       "      <td>90889</td>\n",
       "      <td>6138</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            patient1       patient2  patient1_id  patient2_id  \\\n",
       "423     patient-4074  patient-10139         4074        10139   \n",
       "9670    patient-4074  patient-26572         4074        26572   \n",
       "16410  patient-90889  patient-84020        90889        84020   \n",
       "17072  patient-90889  patient-67648        90889        67648   \n",
       "19221  patient-90889   patient-6138        90889         6138   \n",
       "\n",
       "       jaccard_similarity  same_gender  same_age_bucket  is_similar  \n",
       "423              0.304348        False            False        True  \n",
       "9670             0.300000         True             True        True  \n",
       "16410            0.344828         True            False        True  \n",
       "17072            0.400000        False            False        True  \n",
       "19221            0.333333         True            False        True  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patient_similarity_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd23b146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_node</th>\n",
       "      <th>target_node</th>\n",
       "      <th>patient1_id</th>\n",
       "      <th>patient2_id</th>\n",
       "      <th>jaccard_similarity</th>\n",
       "      <th>same_gender</th>\n",
       "      <th>same_age_bucket</th>\n",
       "      <th>is_similar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>patient-4074</td>\n",
       "      <td>patient-10139</td>\n",
       "      <td>4074</td>\n",
       "      <td>10139</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9670</th>\n",
       "      <td>patient-4074</td>\n",
       "      <td>patient-26572</td>\n",
       "      <td>4074</td>\n",
       "      <td>26572</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16410</th>\n",
       "      <td>patient-90889</td>\n",
       "      <td>patient-84020</td>\n",
       "      <td>90889</td>\n",
       "      <td>84020</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17072</th>\n",
       "      <td>patient-90889</td>\n",
       "      <td>patient-67648</td>\n",
       "      <td>90889</td>\n",
       "      <td>67648</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19221</th>\n",
       "      <td>patient-90889</td>\n",
       "      <td>patient-6138</td>\n",
       "      <td>90889</td>\n",
       "      <td>6138</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         source_node    target_node  patient1_id  patient2_id  \\\n",
       "423     patient-4074  patient-10139         4074        10139   \n",
       "9670    patient-4074  patient-26572         4074        26572   \n",
       "16410  patient-90889  patient-84020        90889        84020   \n",
       "17072  patient-90889  patient-67648        90889        67648   \n",
       "19221  patient-90889   patient-6138        90889         6138   \n",
       "\n",
       "       jaccard_similarity  same_gender  same_age_bucket  is_similar  \n",
       "423              0.304348        False            False        True  \n",
       "9670             0.300000         True             True        True  \n",
       "16410            0.344828         True            False        True  \n",
       "17072            0.400000        False            False        True  \n",
       "19221            0.333333         True            False        True  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rename column patient1 to source and patient2 to target\n",
    "patient_similarity_df.rename(columns={'patient1': 'source_node', 'patient2': 'target_node'}, inplace=True)\n",
    "patient_similarity_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b07df0",
   "metadata": {},
   "source": [
    "# Create R-GCN and train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b798fed9",
   "metadata": {},
   "source": [
    "### DEBUG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb29d9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get node types\n",
    "# node_types = {node_type: [] for node_type in ['patient', 'diagnosis', 'procedure']}\n",
    "# print(f\"node_types: {node_types}\")\n",
    "\n",
    "    \n",
    "# # Create mappings from original node IDs to new indices for each node type\n",
    "# node_mappings = {node_type: {} for node_type in node_types}\n",
    "\n",
    "# print(f\"node_mappings: {node_mappings}\")\n",
    "# i=0\n",
    "# for node, attr in ntx_graph.nodes(data=True):\n",
    "#     node_type = attr['type']\n",
    "#     if i ==0:\n",
    "#         print(f\"node: {node}\")\n",
    "#         print(f\"attr: {attr}\")\n",
    "#         print(f\"node_type: {node_type}\")\n",
    "\n",
    "#     if node not in node_mappings[node_type]:\n",
    "#         node_mappings[node_type][node] = len(node_mappings[node_type])\n",
    "\n",
    "#         i+=1\n",
    "#         print(f\"node_mappings[{node_type}][{node}]: {node_mappings[node_type][node]}\")\n",
    "#         print(f\"node_mappings[node_type][node]: {node_mappings[node_type][node]}\")\n",
    "\n",
    "#     if i==3:\n",
    "#         break\n",
    "\n",
    "# PROMPT:\n",
    "# Create a relational graph neural network for contrastive learning. The objective is to predict patient similarity. \n",
    "# The data is in the networkx graph named ntx_graph. It contains 3 types of nodes: patients, diagnosis and procedure.\n",
    "# It has edges with the relation of has_diagnosis and had_procedure. \n",
    "# The dataframe patient_similarity_df contains patient similarity score in the column \"jaccard_similarity\". It has source node in column source_node and target node in column target_node. The similar rows have the column is_similar=True and dissimilar rows have is_similar=False.\n",
    "# Create a relational graph neural network that uses the training data derived from ntx_graph and validation data derived from patient_similarity_df.\n",
    "# Train and validate the model and print the loss in every iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3001deb1",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17c1ab39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting NetworkX graph to HeteroData...\n",
      "type data: <class 'torch_geometric.data.hetero_data.HeteroData'>, type node_mappings: <class 'dict'>\n",
      "Using 11513 patients for training and 117 patients for testing\n",
      "data: HeteroData(\n",
      "  train_mask=[11630],\n",
      "  test_mask=[11630],\n",
      "  patient={ x=[11630, 11630] },\n",
      "  diagnosis={ x=[4680, 4680] },\n",
      "  procedure={ x=[1344, 1344] },\n",
      "  (patient, has_diagnosis, diagnosis)={ edge_index=[2, 123987] },\n",
      "  (patient, has_procedure, procedure)={ edge_index=[2, 48741] }\n",
      ")\n",
      "data keys: ['edge_index', 'x', 'train_mask', 'test_mask']\n",
      "data['patient'].x: torch.Size([11630, 11630])\n",
      "data['diagnosis'].x: torch.Size([4680, 4680])\n",
      "data['procedure'].x: torch.Size([1344, 1344])\n",
      "data['patient', 'has_diagnosis', 'diagnosis'].edge_index: torch.Size([2, 123987])\n",
      "data['patient', 'has_procedure', 'procedure'].edge_index: torch.Size([2, 48741])\n",
      "Processing similarity data...\n",
      "Created 50000 training pairs from 50000 samples.\n",
      "Using device: cpu\n",
      "Training model...\n",
      "Epoch: 010, Loss: 0.5760, Test Accuracy: 1.0000\n",
      "Epoch: 020, Loss: 0.0662, Test Accuracy: 1.0000\n",
      "Epoch: 030, Loss: 0.0428, Test Accuracy: 1.0000\n",
      "Epoch: 040, Loss: 0.0276, Test Accuracy: 1.0000\n",
      "Epoch: 050, Loss: 0.0207, Test Accuracy: 1.0000\n",
      "Epoch: 060, Loss: 0.0175, Test Accuracy: 1.0000\n",
      "Epoch: 070, Loss: 0.0158, Test Accuracy: 1.0000\n",
      "Epoch: 080, Loss: 0.0148, Test Accuracy: 1.0000\n",
      "Epoch: 090, Loss: 0.0142, Test Accuracy: 1.0000\n",
      "Epoch: 100, Loss: 0.0136, Test Accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.transforms as T\n",
    "import torch_geometric\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.nn import GraphConv\n",
    "\n",
    "# Convert NetworkX graph to PyTorch Geometric HeteroData\n",
    "def convert_to_hetero_data(nx_graph):\n",
    "    \"\"\"\n",
    "    Convert a NetworkX graph to PyTorch Geometric HeteroData format.\n",
    "    The function assumes the graph has node attributes 'type' and edge attributes 'relation'.\n",
    "\n",
    "    returns:\n",
    "        data: HeteroData object containing the graph data.\n",
    "            data = HeteroData(\n",
    "                patient={ x=[11630, 11630] },\n",
    "                diagnosis={ x=[4680, 4680] },\n",
    "                procedure={ x=[1344, 1344] },\n",
    "                (patient, has_diagnosis, diagnosis)={ edge_index=[2, 123987] },\n",
    "                (patient, has_procedure, procedure)={ edge_index=[2, 48741] }\n",
    "                )\n",
    "        node_mappings: Dictionary mapping original node IDs to new indices for each node type.\n",
    "        The keys are node types and the values are dictionaries mapping original node IDs to new indices.\n",
    "            node_mappings[patient][patient-4074]: 0\n",
    "            node_mappings[patient][patient-90889]: 1\n",
    "            node_mappings[patient][patient-72753]: 2\n",
    "            etc.\n",
    "            node_mappings[diagnosis][diagnosis-1234]: 0\n",
    "            node_mappings[diagnosis][diagnosis-5678]: 1\n",
    "            etc.\n",
    "            node_mappings[procedure][procedure-1234]: 0\n",
    "            node_mappings[procedure][procedure-5678]: 1\n",
    "            node_mappings[procedure][procedure-91011]: 2\n",
    "            etc.\n",
    "    \"\"\"\n",
    "    data = HeteroData()\n",
    "    \n",
    "    # Define node types\n",
    "    node_types_list = ['patient', 'diagnosis', 'procedure']\n",
    "    \n",
    "    # Create mappings from original node IDs to new indices for each node type\n",
    "    # node_mappings: {'patient': {}, 'diagnosis': {}, 'procedure': {}}\n",
    "    node_mappings = {node_type: {} for node_type in node_types_list}\n",
    "\n",
    "    # Populate node mappings\n",
    "    for node, attr in nx_graph.nodes(data=True):\n",
    "\n",
    "        # get type of node from attribute\n",
    "        # e.g., attr: {'gender': 'M', 'age_bucket': 80, 'hadm_id': 137421, 'type': 'patient'}\n",
    "        node_type = attr['type']\n",
    "\n",
    "        # if type is patient, diagnosis or procedure, add to node_mappings\n",
    "        # e.g., node_type: patient\n",
    "        if node_type in node_mappings:\n",
    "\n",
    "            # if specific patient, diagnosis or procedure node is not in the mapping, add it and assign a new index\n",
    "            # e.g., node: patient-4074\n",
    "            if node not in node_mappings[node_type]:\n",
    "\n",
    "                # Assign a new index to the node in the mapping\n",
    "                # e.g., node_mappings[patient][patient-4074] = 0\n",
    "                node_mappings[node_type][node] = len(node_mappings[node_type])\n",
    "    \n",
    "    # Add node features (using one-hot encoding)\n",
    "    for node_type, mapping in node_mappings.items():\n",
    "        num_nodes = len(mapping)\n",
    "\n",
    "        # create matrix of size (num_nodes, num_nodes) with 1s on the diagonal and 0s elsewhere\n",
    "        # e.g., data['patient'].x = torch.eye(num_nodes)\n",
    "        if num_nodes > 0:\n",
    "            data[node_type].x = torch.eye(num_nodes)\n",
    "        else:\n",
    "            # Handle case where a node type might have 0 nodes\n",
    "            data[node_type].x = torch.empty((0, 0), dtype=torch.float)\n",
    "\n",
    "    # Define edge types based on relations found in the graph\n",
    "    edge_types_relations = {\n",
    "        'has_diagnosis': ('patient', 'has_diagnosis', 'diagnosis'),\n",
    "        'has_procedure': ('patient', 'has_procedure', 'procedure')\n",
    "    }\n",
    "\n",
    "    # Initialize edge index storage\n",
    "    for src_type, rel, dst_type in edge_types_relations.values():\n",
    "\n",
    "        # Initialize edge_index for each relation\n",
    "        # e.g., data['patient', 'has_diagnosis', 'diagnosis'].edge_index = torch.empty((2, 0), dtype=torch.long)\n",
    "        # row 0: source node indices (e.g. from patient)\n",
    "        # row 1: destination node indices (e.g. to diagnosis)\n",
    "         data[src_type, rel, dst_type].edge_index = torch.empty((2, 0), dtype=torch.long)\n",
    "\n",
    "    # Add edges\n",
    "    edge_indices_dict = {rel: [[], []] for rel in edge_types_relations.keys()}\n",
    "\n",
    "    for u, v, key, attr in nx_graph.edges(keys=True, data=True):\n",
    "        relation = attr.get('relation')\n",
    "        if relation in edge_types_relations:\n",
    "            src_type, _, dst_type = edge_types_relations[relation]\n",
    "            \n",
    "            # Determine the correct source and destination based on node types\n",
    "            u_type = nx_graph.nodes[u]['type']\n",
    "            v_type = nx_graph.nodes[v]['type']\n",
    "\n",
    "            # Map original node IDs to new indices\n",
    "            if u_type == src_type and v_type == dst_type:\n",
    "                if u in node_mappings[src_type] and v in node_mappings[dst_type]:\n",
    "                    src_idx = node_mappings[src_type][u]\n",
    "                    dst_idx = node_mappings[dst_type][v]\n",
    "                    edge_indices_dict[relation][0].append(src_idx)\n",
    "                    edge_indices_dict[relation][1].append(dst_idx)\n",
    "            elif u_type == dst_type and v_type == src_type: # Handle potential reverse direction in source data\n",
    "                 if v in node_mappings[src_type] and u in node_mappings[dst_type]:\n",
    "                    src_idx = node_mappings[src_type][v]\n",
    "                    dst_idx = node_mappings[dst_type][u]\n",
    "                    edge_indices_dict[relation][0].append(src_idx)\n",
    "                    edge_indices_dict[relation][1].append(dst_idx)\n",
    "\n",
    "\n",
    "    # Assign edge indices to the HeteroData object\n",
    "    for relation, (src_type, rel_key, dst_type) in edge_types_relations.items():\n",
    "        # Convert edge indices to tensor\n",
    "        indices = torch.tensor(edge_indices_dict[relation], dtype=torch.long)\n",
    "\n",
    "        # Ensure edge_index is shape (2, num_edges) even if empty\n",
    "        data[src_type, rel_key, dst_type].edge_index = indices.view(2, -1)\n",
    "\n",
    "    return data, node_mappings\n",
    "\n",
    "# Create RGCN model for contrastive learning\n",
    "class RGCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels, metadata):\n",
    "        \"\"\"\n",
    "        Initialize the RGCN model.\n",
    "        Args:\n",
    "            hidden_channels (int): Number of hidden channels for the graph convolution layers.\n",
    "            out_channels (int): Number of output channels for the projection head.\n",
    "            metadata (tuple): Metadata containing node types and edge types.\n",
    "                              metadata[0] is a list of node types\n",
    "                              metadata[1] is a list of edge types.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        # Dynamically create convolutions based on metadata\n",
    "        # Two dicts hold graph convolution layers for each edge type present in the graph\n",
    "        conv_dict1 = {}\n",
    "        conv_dict2 = {}\n",
    "\n",
    "        # Iterate over edge types to create two convolution layers for each edge type\n",
    "        # metadata[1] is a list of tuples of the form ('src_node_type', 'relation', 'dst_node_type')        \n",
    "        for edge_type in metadata[1]:\n",
    "\n",
    "            # Use -1 for input channels to infer automatically\n",
    "            conv_dict1[edge_type] = GraphConv(-1, hidden_channels)\n",
    "            conv_dict2[edge_type] = GraphConv(hidden_channels, hidden_channels)\n",
    "\n",
    "        # HeteroConv allows for different convolution types for different edge types\n",
    "        # dictionaries of edge convolution layers are used to create hetero convolution layers\n",
    "        # aggr=sum specifies that messages from different edge types arriving at the same node should be summed up\n",
    "        self.conv1 = torch_geometric.nn.HeteroConv(conv_dict1, aggr='sum')\n",
    "        self.conv2 = torch_geometric.nn.HeteroConv(conv_dict2, aggr='sum')\n",
    "\n",
    "        # Projection head specifically for processing patient nodes and output embeddings for contrastive learning\n",
    "        # The projection head is a simple feedforward network with two linear layers and ReLU activation\n",
    "        # The input size to the linear layer depends on the output of conv2 for 'patient' nodes\n",
    "        self.patient_proj = nn.Sequential(\n",
    "            nn.Linear(hidden_channels, hidden_channels), # Adjust input size if needed\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_channels, out_channels)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        \"\"\"\n",
    "        Forward pass through the model.\n",
    "        Args:\n",
    "            x_dict (dict): Dictionary of node features for each node type.\n",
    "            edge_index_dict (dict): Dictionary of edge indices for each edge type.\n",
    "        Returns:\n",
    "            torch.Tensor: Projected patient embeddings.\n",
    "        \"\"\"\n",
    "\n",
    "        # First layer\n",
    "        x_dict = self.conv1(x_dict, edge_index_dict)\n",
    "        x_dict = {key: F.relu(x) for key, x in x_dict.items()}\n",
    "        \n",
    "        # Second layer\n",
    "        x_dict = self.conv2(x_dict, edge_index_dict)\n",
    "\n",
    "        # No ReLU after the second layer before projection\n",
    "        \n",
    "        # Project patient embeddings for contrastive learning\n",
    "        # Check if 'patient' key exists before projecting\n",
    "        if 'patient' in x_dict:\n",
    "            patient_emb = self.patient_proj(x_dict['patient'])\n",
    "            return patient_emb\n",
    "        else:\n",
    "            # Handle cases where 'patient' embeddings might not be produced (e.g., graph structure)\n",
    "            return None # Or raise an error, or return an empty tensor\n",
    "\n",
    "# Create a contrastive loss function\n",
    "class ContrastiveLoss(nn.Module):\n",
    "    def __init__(self, margin=0.5):\n",
    "        \"\"\"\n",
    "        Initialize the Contrastive Loss function.\n",
    "        Args:\n",
    "            margin (float): Margin is the radius of the circle in which the positive pairs are located.\n",
    "        \"\"\"\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "        \n",
    "    def forward(self, embeddings, pairs, labels):\n",
    "        \"\"\"\n",
    "        Forward pass for the contrastive loss.\n",
    "        Args:\n",
    "            embeddings (torch.Tensor): Node embeddings from the model.\n",
    "            pairs (torch.Tensor): Pairs of node indices for which to compute the loss.\n",
    "            labels (torch.Tensor): Labels indicating whether pairs are similar (0) or dissimilar (1).\n",
    "\n",
    "        \"\"\"\n",
    "        # Ensure pairs and labels are on the same device as embeddings\n",
    "        pairs = pairs.to(embeddings.device)\n",
    "        labels = labels.to(embeddings.device)\n",
    "\n",
    "        # Extract embeddings for pairs\n",
    "        # Ensure indices in pairs are within the bounds of embeddings (prevents out of bound errors)\n",
    "        valid_indices_mask = (pairs[:, 0] < embeddings.size(0)) & (pairs[:, 1] < embeddings.size(0))\n",
    "\n",
    "        # only keep valid pairs and labels\n",
    "        # valid_pairs: pairs where both indices are within bounds\n",
    "        valid_pairs = pairs[valid_indices_mask]\n",
    "        valid_labels = labels[valid_indices_mask]\n",
    "\n",
    "        if valid_pairs.size(0) == 0:\n",
    "            return torch.tensor(0.0, device=embeddings.device, requires_grad=True) # Return zero loss if no valid pairs\n",
    "\n",
    "        embeddings1 = embeddings[valid_pairs[:, 0]]\n",
    "        embeddings2 = embeddings[valid_pairs[:, 1]]\n",
    "        \n",
    "        # Calculate Euclidean distance\n",
    "        distances = F.pairwise_distance(embeddings1, embeddings2)\n",
    "        \n",
    "        # Calculate loss based on labels (0 for similar, 1 for dissimilar)\n",
    "        # Loss for similar pairs (label=0): distance^2\n",
    "        # Loss for dissimilar pairs (label=1): max(0, margin - distance)^2\n",
    "        loss_similar = (1 - valid_labels) * torch.pow(distances, 2)\n",
    "        loss_dissimilar = valid_labels * torch.pow(torch.clamp(self.margin - distances, min=0.0), 2)\n",
    "        \n",
    "        loss = loss_similar + loss_dissimilar\n",
    "        return loss.mean()\n",
    "\n",
    "# Process NetworkX graph\n",
    "print(\"Converting NetworkX graph to HeteroData...\")\n",
    "data, node_mappings = convert_to_hetero_data(ntx_graph)\n",
    "\n",
    "print(f\"type data: {type(data)}, type node_mappings: {type(node_mappings)}\")\n",
    "\n",
    "# Create a training-validation split by masking nodes rather than slicing the data\n",
    "# We'll use a random subset of patient nodes for inference\n",
    "import random\n",
    "\n",
    "# Get list of patient indices\n",
    "patient_indices = list(range(data['patient'].x.shape[0]))\n",
    "\n",
    "# Shuffle the indices for randomness\n",
    "random.shuffle(patient_indices)\n",
    "\n",
    "# Split into training (99%) and inference (1%)\n",
    "split_idx = int(0.99 * len(patient_indices))\n",
    "train_indices = patient_indices[:split_idx]\n",
    "test_indices = patient_indices[split_idx:]\n",
    "\n",
    "print(f\"Using {len(train_indices)} patients for training and {len(test_indices)} patients for testing\")\n",
    "\n",
    "# Create a mask for training and testing\n",
    "train_mask = torch.zeros(data['patient'].x.shape[0], dtype=torch.bool)\n",
    "train_mask[train_indices] = True\n",
    "\n",
    "# We'll keep the original data object intact, and use masks during training/testing\n",
    "data.train_mask = train_mask\n",
    "\n",
    "data.test_mask = torch.zeros(data['patient'].x.shape[0], dtype=torch.bool)\n",
    "data.test_mask[test_indices] = True\n",
    "\n",
    "\n",
    "# print first 5 elements of data\n",
    "print(f\"data: {data}\")\n",
    "print(f\"data keys: {data.keys()}\")\n",
    "print(f\"data['patient'].x: {data['patient'].x.shape}\")\n",
    "print(f\"data['diagnosis'].x: {data['diagnosis'].x.shape}\")\n",
    "print(f\"data['procedure'].x: {data['procedure'].x.shape}\")\n",
    "print(f\"data['patient', 'has_diagnosis', 'diagnosis'].edge_index: {data['patient', 'has_diagnosis', 'diagnosis'].edge_index.shape}\")\n",
    "print(f\"data['patient', 'has_procedure', 'procedure'].edge_index: {data['patient', 'has_procedure', 'procedure'].edge_index.shape}\")\n",
    "\n",
    "\n",
    "# Add reverse edges to make the graph effectively undirected for message passing\n",
    "transform = T.ToUndirected()\n",
    "data = transform(data)\n",
    "\n",
    "# Create a lookup from original patient node ID to new sequential index\n",
    "patient_node_lookup = {node: idx for node, idx in node_mappings.get('patient', {}).items()}\n",
    "\n",
    "# Process similarity data for training\n",
    "print(\"Processing similarity data...\")\n",
    "sim_pairs_list = []\n",
    "sim_labels_list = []\n",
    "\n",
    "# Consider using a subset for faster training/debugging if the dataset is large\n",
    "# Determine sample size (e.g., 50k or full dataset)\n",
    "sample_size = min(50000, len(patient_similarity_df))\n",
    "\n",
    "# Use random sampling if taking a subset\n",
    "subset_df = patient_similarity_df.sample(n=sample_size, random_state=42) if sample_size < len(patient_similarity_df) else patient_similarity_df\n",
    "\n",
    "\n",
    "for _, row in subset_df.iterrows():\n",
    "    source = row['source_node']\n",
    "    target = row['target_node']\n",
    "    # Check if both source and target patients are in our mapping\n",
    "    if source in patient_node_lookup and target in patient_node_lookup:\n",
    "        source_idx = patient_node_lookup[source]\n",
    "        target_idx = patient_node_lookup[target]\n",
    "        sim_pairs_list.append([source_idx, target_idx])\n",
    "        # Use 0 for similar, 1 for dissimilar for the contrastive loss formula used\n",
    "        sim_labels_list.append(0.0 if row['is_similar'] else 1.0)\n",
    "\n",
    "if not sim_pairs_list:\n",
    "     raise ValueError(\"No valid training pairs found. Check patient IDs in similarity data and graph.\")\n",
    "\n",
    "sim_pairs = torch.tensor(sim_pairs_list, dtype=torch.long)\n",
    "sim_labels = torch.tensor(sim_labels_list, dtype=torch.float)\n",
    "\n",
    "print(f\"Created {len(sim_pairs)} training pairs from {sample_size} samples.\")\n",
    "\n",
    "# --- Model, Optimizer, and Training Setup ---\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Ensure data is on the correct device\n",
    "data = data.to(device)\n",
    "sim_pairs = sim_pairs.to(device)\n",
    "sim_labels = sim_labels.to(device)\n",
    "\n",
    "\n",
    "# Create the model\n",
    "hidden_channels = 64\n",
    "out_channels = 32\n",
    "model = RGCN(hidden_channels, out_channels, data.metadata()).to(device)\n",
    "\n",
    "# Set up optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4) # Added weight decay\n",
    "criterion = ContrastiveLoss(margin=1.0) # Adjusted margin\n",
    "\n",
    "# Training loop\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Get patient embeddings\n",
    "    patient_embeddings = model(data.x_dict, data.edge_index_dict)\n",
    "    \n",
    "    if patient_embeddings is None or patient_embeddings.size(0) == 0:\n",
    "         print(\"Warning: No patient embeddings generated.\")\n",
    "         return 0.0 # Or handle appropriately\n",
    "\n",
    "    # Compute loss using only the patient embeddings\n",
    "    loss = criterion(patient_embeddings, sim_pairs, sim_labels)\n",
    "    \n",
    "    if loss.requires_grad:\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        return loss.item()\n",
    "    else:\n",
    "        # Handle cases where loss does not require gradients (e.g., no valid pairs)\n",
    "        print(\"Warning: Loss does not require gradients.\")\n",
    "        return loss.item() # Return the scalar value\n",
    "\n",
    "# Train the model\n",
    "print(\"Training model...\")\n",
    "num_epochs = 100 # Increased epochs\n",
    "losses = [] # Track losses for visualization\n",
    "\n",
    "# Track both training loss and validation performance\n",
    "losses = []\n",
    "accuracies = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    loss = train()\n",
    "    losses.append(loss)\n",
    "    \n",
    "    # Evaluate on test set periodically\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            # Get embeddings for all patients\n",
    "            patient_embeddings = model(data.x_dict, data.edge_index_dict)\n",
    "            \n",
    "            # Create pairs from test patients for evaluation\n",
    "            test_pairs = []\n",
    "            test_labels = []\n",
    "            \n",
    "            # Get test patient indices\n",
    "            test_indices_list = test_indices\n",
    "            \n",
    "            # Sample some pairs from test patients for evaluation\n",
    "            for i in range(len(test_indices_list)):\n",
    "                for j in range(i+1, len(test_indices_list)):\n",
    "                    test_pairs.append([test_indices_list[i], test_indices_list[j]])\n",
    "                    # Determine similarity based on Euclidean distance\n",
    "                    emb_i = patient_embeddings[test_indices_list[i]]\n",
    "                    emb_j = patient_embeddings[test_indices_list[j]]\n",
    "                    distance = F.pairwise_distance(emb_i.unsqueeze(0), emb_j.unsqueeze(0))\n",
    "                    # Consider patients similar if distance < 0.5 * margin\n",
    "                    test_labels.append(1.0 if distance > 0.5 else 0.0)\n",
    "            \n",
    "            # Calculate accuracy if we have test pairs\n",
    "            accuracy = 0.0\n",
    "            if test_pairs:\n",
    "                test_pairs = torch.tensor(test_pairs, device=device)\n",
    "                test_labels = torch.tensor(test_labels, device=device)\n",
    "                \n",
    "                # Predict similarities\n",
    "                emb1 = patient_embeddings[test_pairs[:, 0]]\n",
    "                emb2 = patient_embeddings[test_pairs[:, 1]]\n",
    "                distances = F.pairwise_distance(emb1, emb2)\n",
    "                predictions = (distances > 0.5).float()\n",
    "                \n",
    "                # Calculate accuracy\n",
    "                correct = (predictions == test_labels).sum().item()\n",
    "                accuracy = correct / len(test_labels)\n",
    "            \n",
    "            accuracies.append(accuracy)\n",
    "        \n",
    "        print(f'Epoch: {epoch+1:03d}, Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}')\n",
    "    \n",
    "    # For epochs where we don't evaluate, just append the last accuracy\n",
    "    elif epoch > 0 and (epoch % 10 != 0):\n",
    "        if accuracies:\n",
    "            accuracies.append(accuracies[-1])\n",
    "\n",
    "# Plot training loss\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, num_epochs+1), losses)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss over Epochs')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "print(\"Training finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc682831",
   "metadata": {},
   "source": [
    "# Save and Load Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8367a3b",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "456a8352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to d:\\Repos\\ut-health-final-proj\\models\\rgcn_model.pth\n"
     ]
    }
   ],
   "source": [
    "# save the model to a file\n",
    "MODEL_FILE_NAME = f\"{CURR_DIR_PATH}\\\\models\\\\rgcn_model.pth\"\n",
    "torch.save(model.state_dict(), MODEL_FILE_NAME)\n",
    "print(f\"Model saved to {MODEL_FILE_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99097fe",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4df7411f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from d:\\Repos\\ut-health-final-proj\\models\\rgcn_model.pth\n",
      "Model Summary:\n",
      "RGCN(\n",
      "  (conv1): HeteroConv(num_relations=4)\n",
      "  (conv2): HeteroConv(num_relations=4)\n",
      "  (patient_proj): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=64, out_features=32, bias=True)\n",
      "  )\n",
      ")\n",
      "Output Data:\n",
      "patient_embeddings: tensor([[ 0.3316,  0.5133, -0.6555,  ..., -0.0071,  0.1463, -0.1359],\n",
      "        [ 0.2440,  0.0956, -0.0600,  ...,  0.1125,  0.1494,  0.0500],\n",
      "        [ 0.4200,  0.1742, -0.3764,  ...,  0.2072,  0.0849,  0.0077],\n",
      "        ...,\n",
      "        [ 0.2390,  0.3239, -0.5120,  ..., -0.0569,  0.3366, -0.0210],\n",
      "        [ 0.5151,  0.7061, -0.8309,  ...,  0.1171,  0.0572, -0.2839],\n",
      "        [ 0.1839, -0.0029,  0.0264,  ...,  0.1250,  0.1372,  0.0826]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "\n",
      "Model Summary Finished.\n",
      "Model summary printed.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# load the model from a file\n",
    "def load_model(model, file_path):\n",
    "    model.load_state_dict(torch.load(file_path))\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "# load the model from a file\n",
    "model = RGCN(hidden_channels, out_channels, data.metadata()).to(device)\n",
    "model = load_model(model, MODEL_FILE_NAME)\n",
    "print(f\"Model loaded from {MODEL_FILE_NAME}\")\n",
    "\n",
    "\n",
    "# print model summary\n",
    "def print_model_summary(model):\n",
    "    print(\"Model Summary:\")\n",
    "    print(model)\n",
    "    # print(\"\\nModel Parameters:\")\n",
    "    # for name, param in model.named_parameters():\n",
    "    #     if param.requires_grad:\n",
    "    #         print(f\"{name}: {param.data.size()}\")\n",
    "    # print(\"\\nModel Forward Pass:\")\n",
    "    # for name, param in model.named_parameters():\n",
    "    #     if param.requires_grad:\n",
    "    #         print(f\"{name}: {param.data.size()}\")\n",
    "    # print(\"\\nModel Forward Pass:\")\n",
    "    # print(\"Input Data:\")\n",
    "    # print(f\"data.x_dict: {data.x_dict}\")\n",
    "    # print(f\"data.edge_index_dict: {data.edge_index_dict}\")\n",
    "    print(\"Output Data:\")\n",
    "    print(f\"patient_embeddings: {model(data.x_dict, data.edge_index_dict)}\")\n",
    "    print(\"\\nModel Summary Finished.\")\n",
    "\n",
    "print_model_summary(model)\n",
    "# print model summary\n",
    "print(\"Model summary printed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a738bf4",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4fabff18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample inference completed with 93.00% accuracy\n",
      "Sample size: 100\n",
      "   source_idx  target_idx  predicted_similarity  actual_label    source_node  \\\n",
      "0        7069        9776              0.999994           0.0   patient-7890   \n",
      "1        7045       10490              0.490896           1.0   patient-1317   \n",
      "2        2734        4602              0.999994           0.0  patient-15660   \n",
      "3        5957        6595              0.528214           1.0  patient-48666   \n",
      "4         667        4803              0.777140           0.0  patient-11687   \n",
      "5        1896        3672              0.903138           0.0  patient-24458   \n",
      "6        1154       10578              0.966150           0.0  patient-25596   \n",
      "7        7386        8384              0.465685           1.0  patient-70169   \n",
      "8        7116       10445              0.526530           1.0  patient-12025   \n",
      "9         742        2934              0.999994           0.0   patient-6551   \n",
      "\n",
      "     target_node  predicted_label  is_correct  \n",
      "0  patient-18077              0.0        True  \n",
      "1  patient-64881              1.0        True  \n",
      "2  patient-16496              0.0        True  \n",
      "3  patient-10200              0.0       False  \n",
      "4  patient-23427              0.0        True  \n",
      "5  patient-20170              0.0        True  \n",
      "6  patient-90339              0.0        True  \n",
      "7  patient-30378              1.0        True  \n",
      "8  patient-52398              0.0       False  \n",
      "9  patient-10764              0.0        True  \n",
      "Saved embeddings for 11630 patients, each with 32 dimensions\n"
     ]
    }
   ],
   "source": [
    "# Get patient embeddings with the trained model\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    # Generate patient embeddings\n",
    "    patient_embeddings = model(data.x_dict, data.edge_index_dict)\n",
    "    \n",
    "    # Select a small sample of patient pairs for inference\n",
    "    num_samples = 100\n",
    "    sample_indices = np.random.choice(len(sim_pairs), num_samples, replace=False)\n",
    "    \n",
    "    sample_pairs = sim_pairs[sample_indices]\n",
    "    sample_labels = sim_labels[sample_indices]\n",
    "    \n",
    "    # Extract embeddings for the sampled pairs\n",
    "    embeddings1 = patient_embeddings[sample_pairs[:, 0]]\n",
    "    embeddings2 = patient_embeddings[sample_pairs[:, 1]]\n",
    "    \n",
    "    # Calculate Euclidean distances between pairs\n",
    "    distances = F.pairwise_distance(embeddings1, embeddings2).cpu().numpy()\n",
    "    \n",
    "    # Convert to similarity scores (inverse of distance)\n",
    "    similarities = 1.0 / (1.0 + distances)\n",
    "    \n",
    "    # Prepare results in a DataFrame\n",
    "    result_df = pd.DataFrame({\n",
    "        'source_idx': sample_pairs[:, 0].cpu().numpy(),\n",
    "        'target_idx': sample_pairs[:, 1].cpu().numpy(),\n",
    "        'predicted_similarity': similarities,\n",
    "        'actual_label': sample_labels.cpu().numpy(),  # 0 for similar, 1 for dissimilar\n",
    "    })\n",
    "    \n",
    "    # Map indices back to original patient IDs\n",
    "    reverse_lookup = {idx: node_id for node_id, idx in patient_node_lookup.items()}\n",
    "    result_df['source_node'] = result_df['source_idx'].map(reverse_lookup)\n",
    "    result_df['target_node'] = result_df['target_idx'].map(reverse_lookup)\n",
    "    \n",
    "    # Calculate accuracy based on a threshold\n",
    "    threshold = 0.5\n",
    "    result_df['predicted_label'] = (result_df['predicted_similarity'] < threshold).astype(float)\n",
    "    result_df['is_correct'] = (result_df['predicted_label'] == result_df['actual_label'])\n",
    "    \n",
    "    accuracy = result_df['is_correct'].mean() * 100\n",
    "    \n",
    "    print(f\"Sample inference completed with {accuracy:.2f}% accuracy\")\n",
    "    print(f\"Sample size: {num_samples}\")\n",
    "    print(result_df.head(10))\n",
    "\n",
    "# Store embeddings for all patients\n",
    "all_patient_embeddings = patient_embeddings.cpu().numpy()\n",
    "print(f\"Saved embeddings for {all_patient_embeddings.shape[0]} patients, each with {all_patient_embeddings.shape[1]} dimensions\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
